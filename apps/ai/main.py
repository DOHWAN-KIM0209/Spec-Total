import uvicorn
from common.exception import *
import openai
import os
from dotenv import load_dotenv
from fastapi import FastAPI, status, HTTPException, UploadFile, File
from loguru import logger
from routes import analysis
from io import BytesIO
from core.logger import load_config
from core.settings import settings
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware  # CORS ë¯¸ë“¤ì›¨ì–´ import

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œìš©
import pdfplumber

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
print("ğŸ”‘ OpenAI KEY:", openai.api_key)

app = FastAPI(
    title="[spec] API-AI docs",
    description=""" 
    ## **spec**
    Give some guidance for the job interview based on AI
    - This is a project of D102, SSAFY 10th.
    - Project description on [Notion](https://lshhh.notion.site/preview-AI-3590d9e05aa447c6b92d8f65639632ff?pvs=74)

    Author:
    - Kim kyungran <cookie3478@naver.com>, Leader of D102
    """,
    root_path="/ai",
    openapi_tags=[{"name": "1. analysis", "description": "ë©´ì ‘ ì˜ìƒ ë¶„ì„ ê´€ë ¨ API"},
                  {"name": "2. interview", "description": "ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ê´€ë ¨ API"}],
)

# CORS ì„¤ì • (Reactì™€ ì—°ê²°ì„ ìœ„í•´ í•„ìš”)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # React ì•± ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì†Œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

# Add routers(controllers)
app.include_router(
    analysis.router,
    tags=["1. analysis"],
    prefix="/analysis",
)

# Add custom exception handlers
exception_handlers = {
    RequestValidationError: custom_validation_error_handler,
    FileNotFoundError: custom_file_not_fount_error_handler,
}
for exc, handler in exception_handlers.items():
    app.add_exception_handler(exc, handler)

class ResumeQuestionRequest(BaseModel):
    resume: str

class FollowUpQuestionRequest(BaseModel):
    previous_question: str
    user_answer: str

# âœ… 1. ê³µí†µ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± API
tags = ["2. interview"]
@app.get("/interview/common-questions", tags=["ê³µí†µ ë©´ì ‘ ì§ˆë¬¸"])
async def generate_common_questions():
    """
    ê¸°ë³¸ì ì¸ ê³µí†µ ë©´ì ‘ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” API.
    """
    common_questions = [
        "ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
        "ë³¸ì¸ì˜ ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì§€ì› ë™ê¸°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "5ë…„ í›„ ë³¸ì¸ì˜ ëª¨ìŠµì„ ì–´ë–»ê²Œ ìƒê°í•˜ë‚˜ìš”?",
        "íŒ€ í”„ë¡œì íŠ¸ ê²½í—˜ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.",
        "ë¬¸ì œë¥¼ í•´ê²°í–ˆë˜ ê²½í—˜ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ê°ˆë“± ìƒí™©ì—ì„œ ì–´ë–»ê²Œ ëŒ€ì²˜í–ˆë‚˜ìš”?",
        "ìµœê·¼ ê´€ì‹¬ ìˆëŠ” IT íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì••ë°•ë©´ì ‘ ìƒí™©ì´ë¼ë©´ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        "ì™œ ìš°ë¦¬ íšŒì‚¬ë¥¼ ì„ íƒí–ˆë‚˜ìš”?"
    ]
    return {"common_questions": common_questions}

# âœ… pdfplumber ê¸°ë°˜ ì´ë ¥ì„œ ì§ˆë¬¸ ìƒì„± API
@app.post("/interview/resume-question", tags=tags)
async def generate_resume_question(file: UploadFile = File(...)):
    """
    ì´ë ¥ì„œë¥¼ PDF í˜•ì‹ìœ¼ë¡œ ì—…ë¡œë“œí•˜ë©´ OpenAIë¥¼ í†µí•´ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” API.
    pdfplumberë¥¼ í†µí•´ ë†’ì€ ì •í™•ë„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ.
    """
    try:
        pdf_bytes = await file.read()

        # pdfplumberë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = ""
        with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"

        if not text.strip():
            raise HTTPException(status_code=400, detail="PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        print("ğŸ“¥ ì¶”ì¶œëœ ì´ë ¥ì„œ í…ìŠ¤íŠ¸:", text)

        # GPTì— ì§ˆë¬¸ ìš”ì²­
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{
                "role": "system",
                "content": "ì´ë ¥ì„œë¥¼ ë¶„ì„í•´ì„œ, ì´ë ¥ì„œì— ì‘ì„±ëœ ì–¸ì–´ê°€ í•œêµ­ì–´ë©´ í•œêµ­ì–´ë¡œë§Œ, ì˜ì–´ë©´ ì˜ì–´ë¡œë§Œ ëœ ìì—°ìŠ¤ëŸ½ê³  ì ì ˆí•œ ë©´ì ‘ ì§ˆë¬¸ì„ 10ê°€ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±í•˜ì„¸ìš”."
            }, {
                "role": "user",
                "content": f"ì´ë ¥ì„œ:\n{text}"
            }]
        )

        return {"question": response["choices"][0]["message"]["content"]}

    except Exception as e:
        print("ğŸ”¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë˜ëŠ” OpenAI ì—ëŸ¬:", e)
        raise HTTPException(status_code=500, detail=str(e))

# âœ… ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± API
@app.post("/interview/follow-up", tags=tags)
async def generate_follow_up_question(request: FollowUpQuestionRequest):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{
                "role": "system",
                "content": "ì§ˆë¬¸ê³¼ ì‚¬ìš©ìì˜ ëŒ€ë‹µì„ ì°¸ê³ í•˜ì—¬ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•˜ë˜, ì‚¬ìš©ìì˜ ëŒ€ë‹µì´ í•œêµ­ì–´ë©´ í•œêµ­ì–´ë¡œ, ì˜ì–´ë©´ ì˜ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì ì ˆí•œ ê¼¬ë¦¬ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”."
            }, {
                "role": "user",
                "content": f"ì§ˆë¬¸: {request.previous_question}\nëŒ€ë‹µ: {request.user_answer}"
            }]
        )
        return {"follow_up_question": response["choices"][0]["message"]["content"]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ì„œë²„ Health Check
@app.get(
    "/",
    summary="ì„œë²„ Health Check",
    status_code=status.HTTP_200_OK,
)
def health_check():
    """ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ 'ok' ë°˜í™˜"""
    return "ok"

if __name__ == "__main__":
    RUN_SERVER_MSG = "Run server"
    if settings.DEBUG:
        RUN_SERVER_MSG = f"NOTE!!! {RUN_SERVER_MSG} as DEBUG mode"
    logger.info(RUN_SERVER_MSG)

    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.DEBUG,
        log_config=load_config(),
    )
